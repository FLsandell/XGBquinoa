{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9523b7",
   "metadata": {},
   "source": [
    "# XGQuinoa\n",
    "\n",
    "### Unrevealing the genomic basis of seed colour using Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab23008",
   "metadata": {},
   "source": [
    "This notebook is part of the publication: (fill when published)\n",
    "\n",
    "All files used within this notebook are available on my GitHub:\n",
    "\n",
    "(c) Felix Leopold Sandell, 19.9.2023\n",
    "\n",
    "Institute of Computational Biology\n",
    "\n",
    "BOKU, Vienna\n",
    "    \n",
    "Contact: felix.sandell@boku.ac.at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa53814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost for Quinoa Accessions (Colours)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776cde9",
   "metadata": {},
   "source": [
    "## Part 1 - Parameter optimization and modell fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84568dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 0/1/2 matrix. The matrix is importet transposed\n",
    "# since pandas is faster importing files with a large number of lines than collumns\n",
    "\n",
    "Quinoa_01 = pd.read_csv('/path/to/input/012/Matrix.txt', sep = \"\\t\")\n",
    "\n",
    "# Set row index\n",
    "Quinoa_01 = Quinoa_01.set_index('ACC')\n",
    "\n",
    "# Transpose the file\n",
    "Quinoa_01 = Quinoa_01.T\n",
    "\n",
    "# Keep sets with all colours. This is only needed for the all-colours LDA and PCA at the \n",
    "# end of the notebook. Remove the # if you want to calculate this. Keep in mind keeping\n",
    "# both tables is memory expensive.\n",
    "\n",
    "# Quinoa_original = Quinoa_01\n",
    "\n",
    "\n",
    "# Import y\n",
    "y = pd.read_csv('path/to/targets/colour/file.txt', sep = \"\\t\")\n",
    "\n",
    "\n",
    "# index y to have the same index as Quinoa_01\n",
    "y_index = y.set_index(Quinoa_01.index)\n",
    "\n",
    "# combine X and y\n",
    "Quinoa_01['Colour'] = y_index\n",
    "\n",
    "# We train our models only on accessions coloured beige, orange and white, therefore\n",
    "# the other accessions are removed\n",
    "\n",
    "Quinoa_01 = Quinoa_01[Quinoa_01.Colour != \"BrightReddischGreen\"]\n",
    "Quinoa_01 = Quinoa_01[Quinoa_01.Colour != \"light\"]\n",
    "Quinoa_01 = Quinoa_01[Quinoa_01.Colour != \"unclear\"]\n",
    "Quinoa_01 = Quinoa_01[Quinoa_01.Colour != \"yellow\"]\n",
    "Quinoa_01 = Quinoa_01[Quinoa_01.Colour != \"dark\"]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter optimisation is calculated using hyperopt, we therefore need functions to\n",
    "# extract informations from trial objects\n",
    "\n",
    "def getBestModelfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['Trained_Model']\n",
    "\n",
    "\n",
    "def getBestLossfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['loss']\n",
    "\n",
    "\n",
    "def getBestRoundsfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['rounds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the search Space for parameter optimization\n",
    "\n",
    "space={ 'learning_rate'     : hp.choice('learning_rate', np.logspace(np.log10(0.005), np.log10(0.2), base = 10, num = 400)),\n",
    "        'max_depth': hp.choice('max_depth', range(10, 32, 1)),\n",
    "        'gamma': hp.choice('gamma', [0.5, 1, 1.5, 2, 3]),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'reg_alpha' : hp.uniform('reg_alpha', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5 , 0.9 ),\n",
    "        'subsample' : hp.uniform('subsample', 0.5,0.9),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 4, 10, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the function for parameter optimization\n",
    "\n",
    "def objective(space):\n",
    "    params = {\"objective\" : \"multi:softprob\", \"num_class\" : 3,\n",
    "                    \"max_depth\" : int(space['max_depth']), \"gamma\" : space['gamma'],\n",
    "                    \"min_child_weight\":int(space['min_child_weight']),\n",
    "                    \"colsample_bytree\" : (space['colsample_bytree']),\n",
    "                    \"subsample\":(space['subsample']),\n",
    "                    \"learning_rate\" :(space['learning_rate']) ,\n",
    "                     \"reg_lambda\" : (space['reg_lambda']),\n",
    "                     \"reg_alpha\": (space['reg_alpha'])}\n",
    "    \n",
    "    xgboost_train = xgb.DMatrix(data=X_train, label=y_train, weight = X_weights)\n",
    "    \n",
    "    #the maximum of rounds is set to 1000, but we have early stopping at round 25\n",
    "    \n",
    "    num_boost_round=1000\n",
    "    \n",
    "    xgb_cv = xgb.cv(dtrain=xgboost_train,  params=params, num_boost_round=num_boost_round, early_stopping_rounds = 20, nfold=4,  metrics = 'auc',seed=8, stratified=True) \n",
    "    \n",
    "    n_rounds = len(xgb_cv[\"test-auc-mean\"])\n",
    "    cv_score = xgb_cv[\"test-auc-mean\"][n_rounds-1]\n",
    "    \n",
    "    print( 'CV finished n_rounds={} cv_score={:7.5f}'.format( n_rounds, cv_score ) )\n",
    "\n",
    "    \n",
    "    print (\"SCORE:\", cv_score)\n",
    "    return {'loss': -cv_score, 'status': STATUS_OK,'Trained_Model': params, 'rounds' : n_rounds }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be76044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y\n",
    "y = Quinoa_01['Colour'].values\n",
    "X = Quinoa_01.drop(['Colour'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b67409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As working with a unbalanced dataset we set wheights\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=Quinoa_01['Colour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell if you want to add the first 10 principal components, to correct for population\n",
    "# Structure\n",
    "#pca = PCA(n_components=10)\n",
    "#principalComponents_large = pca.fit_transform(X)\n",
    "#X = np.append(X,principalComponents_large, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7864450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lables are encoded and we split the training and the test set based on a random seed\n",
    "# For the publication we used the seeds 0-99. The best performing seed seed, the split reported \n",
    "# in the publication is 47. For clarity and reproducibility we also report the worst seed, which\n",
    "# is 67\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_encoder = le.fit(y)\n",
    "y_encoded = label_encoder.transform(y)\n",
    " \n",
    "seed = 67\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify = y_encoded ,random_state = seed)\n",
    "X_weights, X_test_drop, y_train_drop, y_test_drop = train_test_split(classes_weights, y_encoded, stratify = y_encoded ,random_state = seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hyper Parameter Optimization with 250 rounds of HyperOpt\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=250,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4079612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best performing model from Hyperopt\n",
    "best_model = getBestModelfromTrials(trials)\n",
    "\n",
    "# Get the number of rounds, before early stopping\n",
    "\n",
    "rounds = getBestRoundsfromTrials(trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained parameters for split 67\n",
    "#best_model = {'objective': 'multi:softprob',\n",
    " #'num_class': 3,\n",
    " #'max_depth': 29,\n",
    " #'gamma': 1.5,\n",
    " #'min_child_weight': 9,\n",
    " #'colsample_bytree': 0.8960717627960193,\n",
    " #'subsample': 0.5418254855928383,\n",
    " #'learning_rate': 0.06487585843287937}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13581d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained parameters for split 47\n",
    "    \n",
    "best_model = {'objective': 'multi:softprob',\n",
    "    'num_class': 3,\n",
    "    'max_depth': 25,\n",
    "    'gamma': 1.5,\n",
    "    'min_child_weight': 8,\n",
    "    'colsample_bytree': 0.7193577374394876,\n",
    "    'subsample': 0.6481597809269125,\n",
    "    'learning_rate': 0.020956759830646633}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our model against the Training set\n",
    "\n",
    "xgboost_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "clf=xgb.XGBClassifier(**best_model, n_estimators = 50, eval_metric = \"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "clf.fit(X_train, y_train, sample_weight=X_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict targets\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "classification = sklearn.metrics.classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b58f86",
   "metadata": {},
   "source": [
    "## Part 2 - Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eceb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe without the targets\n",
    "\n",
    "X_df = Quinoa_01.drop(['Colour'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a90a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all feature names\n",
    "\n",
    "orig_feature_names = X_df.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3440e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the original feature names to the model\n",
    "\n",
    "clf.get_booster().feature_names = orig_feature_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79865bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances\n",
    "\n",
    "feats = clf.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with the feature importances\n",
    "\n",
    "features_list = feats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only variants that resulted in a gain of prediction accuracy\n",
    "\n",
    "X_small = X_df.loc[:,features_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057d4d0",
   "metadata": {},
   "source": [
    "## Part 3 - PCAs and LDAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f8576",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a PCA with 2 components\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(X_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a17538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf = principalDf.set_index(Quinoa_01.index)\n",
    "finalDf = pd.concat([principalDf, Quinoa_01[['Colour']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336be65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the PCA on a reduced dataset\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (11,11))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('PCA', fontsize = 20)\n",
    "targets = ['orange', 'beige']\n",
    "colors = ['darkorange', 'darkkhaki']\n",
    "markers = ['o','P']\n",
    "for target, color, marker in zip(targets,colors,markers):\n",
    "    indicesToKeep = finalDf['Colour'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 40\n",
    "               , marker = marker)\n",
    "\n",
    "targets = ['white']\n",
    "colors = [ 'dimgrey']\n",
    "markers = ['o']\n",
    "for target, color, marker in zip(targets,colors,markers):\n",
    "    indicesToKeep = finalDf['Colour'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , edgecolors = color\n",
    "               , s = 40\n",
    "               , marker = marker\n",
    "               , facecolors='none')\n",
    "\n",
    "targets = ['Orange','Beige','White']\n",
    "ax.legend(targets, prop={'size': 12})\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ff731",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a LDA with 2 components\n",
    "y_lda = Quinoa_01[['Colour']].values.ravel()\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X_small, y_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e398a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "\n",
    "ldaDf = pd.DataFrame(data = X_lda\n",
    "             , columns = ['lda component 1', 'lda component 2'])\n",
    "ldaDf = ldaDf.set_index(Quinoa_01.index)\n",
    "finalDf_lda = pd.concat([ldaDf, Quinoa_01[['Colour']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PCA on a reduced dataset\n",
    "\n",
    "fig = plt.figure(figsize = (11,11))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlabel('Linear Discriminant 1', fontsize = 15)\n",
    "ax.set_ylabel('Linear Discriminant 2', fontsize = 15)\n",
    "ax.set_title('LDA', fontsize = 20)\n",
    "targets = ['orange', 'beige']\n",
    "colors = ['darkorange', 'darkkhaki']\n",
    "markers = ['o','P']\n",
    "for target, color, marker in zip(targets,colors,markers):\n",
    "    indicesToKeep = finalDf['Colour'] == target\n",
    "    ax.scatter(finalDf_lda.loc[indicesToKeep, 'lda component 1']\n",
    "               , finalDf_lda.loc[indicesToKeep, 'lda component 2']\n",
    "               , c = color\n",
    "               , s = 40\n",
    "               , marker = marker)\n",
    "\n",
    "targets = ['white']\n",
    "colors = [ 'dimgrey']\n",
    "markers = ['o']\n",
    "for target, color, marker in zip(targets,colors,markers):\n",
    "    indicesToKeep = finalDf['Colour'] == target\n",
    "    ax.scatter(finalDf_lda.loc[indicesToKeep, 'lda component 1']\n",
    "               , finalDf_lda.loc[indicesToKeep, 'lda component 2']\n",
    "               , edgecolors = color\n",
    "               , s = 40\n",
    "               , marker = marker\n",
    "               , facecolors='none')\n",
    "\n",
    "targets = ['Orange','Beige','White']\n",
    "ax.legend(targets, prop={'size': 12})\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e238d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
